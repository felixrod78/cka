-kubect:
  get: listar objetos en el cluster  -o para formato salida --sort-by formato salida json --selector  filtra los resultados
  describe: informacion extensiva
  create: crear objetos -f desde archivo
  apply: igual a create pero permite aplicar sobre un objeto ya creado
  exec: ejecutar comandos dentro del container -c indica el contenedor especifico dentro del pod
  delete: borra objetos
  api-resourcestype : ves todos los recursos del cluster



- kubectl apply -f pod.yml  para crear pods desde archivo
- kubectl expose web --port 80 --type NodePort  exponer el puerto 80 a traves de uno aleatorio
    NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
    kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        98m
    web          NodePort    10.109.126.28   <none>        80:32483/TCP   9s

- kubectl drain node-name  para sacar de manera controlada un nodo del cluster 
    --ignore-daemonsets -- servicios que corren especificamente en dicho nodo
    - solo aplica a pods desplegados como job,replicaset,statefullset,replicationcontroller
- kubectl uncordon <node-name>  para volver a agregar el nodo al cluster

- Upgrade cluster:
  - sudo apt-get update && \ sudo apt-get install -y --allow-change-held-packages kubeadm=1.21.1-00
    kubectl drain control-plane node --ingnore-daemonsets
    kubeadm version
    sudo kubeadm upgrade plan v.1.21.1 solo informa de los elementos a actualizar
    kubeadm upgrade apply v1.21.1
    sudo apt-get install -y --allow-change-held-packages kubectl=1.21.1 kubelet 1.21.1
    sudo systemctl daemon-reload && restart kubelet
    kubectl uncordon control-plane node

- Bck etcd: 
  -  Para realizar un bck:
      ETCDCTL_API=3 etcdctl get cluster.name \
      > --endpoints=https://10.0.1.101:2379 \
      > --cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \
      >  --cert=/home/cloud_user/etcd-certs/etcd-server.crt \
      >  --key=/home/cloud_user/etcd-certs/etcd-server.key 
      cluster.name
      beebox

      ETCDCTL_API=3 etcdctl snapshot save etcd_backup.db \
      > --endpoints=https://10.0.1.101:2379 \
      > --cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \
      >  --cert=/home/cloud_user/etcd-certs/etcd-server.crt \
      >  --key=/home/cloud_user/etcd-certs/etcd-server.key

      ETCDCTL_API=3 etcdctl snapshot restore  etcd_backup.db \
      > --initial-cluster etcd-restore=https://10.0.1.101:2380 \
      > --initial-advertise-peer-urls https://10.0.1.101:2380  \
      > --name etcd-restore \
      >  --data-dir /var/lib/etcd/
      
   
       
   
   
   
   


      
   
   
   
   

      ETCDCTL_API=3 etcdctl get cluster.name  --endpoints=https://10.0.1.101:2379 --cacert=etcd-ca.pem --cert=etcd-server.crt --key=etcd-server.key
      
      
      ETCDCTL_API=3 etcdtl --endpoints $ENDPOINT snapshot save <filename>
      Para realizar un restore:
      ETCDCTL_API=3 etcdtl snapshot restore  <filename>
